{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57358330-59c2-4d31-9dd7-aa1f3b02f3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 4: ENHANCED Data Generation with Advanced Parameter Weighting ---\n",
      "STEP 1: Generating Enhanced Synthetic Data with Intelligent Weighting...\n",
      "‚úÖ Generated 20000 records with realistic feature correlations\n",
      "   Mean Age: 35.9 | Mean Weight: 77.8kg | Mean Sleep: 6.9h\n",
      "‚úÖ Parameter modifiers calculated with advanced weighting\n",
      "\n",
      "‚úÖ Goal Distribution (with advanced weighting):\n",
      "GOAL\n",
      "Endurance      9461\n",
      "Strength       8351\n",
      "Yoga           1453\n",
      "Maintenance     735\n",
      "Name: count, dtype: int64\n",
      "   {'Endurance': 9461, 'Strength': 8351, 'Yoga': 1453, 'Maintenance': 735}\n",
      "\n",
      "‚úÖ Step 1 Complete: Enhanced data with intelligent parameter weighting generated.\n",
      "   Duration range: 12-85 min\n",
      "   Intensity range: 1.5-9.5 RPE\n",
      "\n",
      "STEP 2: Preprocessing features (Encoding + Scaling)...\n",
      "‚úÖ Step 2 Complete: Train/Test split with stratification (train: 16000, test: 4000)\n",
      "\n",
      "STEP 3a: Training Goal Classifier with Cross-Validation...\n",
      "\n",
      "‚úÖ Step 1 Complete: Enhanced data with intelligent parameter weighting generated.\n",
      "   Duration range: 12-85 min\n",
      "   Intensity range: 1.5-9.5 RPE\n",
      "\n",
      "STEP 2: Preprocessing features (Encoding + Scaling)...\n",
      "‚úÖ Step 2 Complete: Train/Test split with stratification (train: 16000, test: 4000)\n",
      "\n",
      "STEP 3a: Training Goal Classifier with Cross-Validation...\n",
      "‚úÖ Goal Classifier Training Accuracy: 0.9999\n",
      "‚úÖ Goal Classifier Test Accuracy: 0.9835\n",
      "‚úÖ Goal Classifier CV Scores: 0.9850 (+/- 0.0024)\n",
      "‚úÖ Goal Classes: ['Endurance' 'Maintenance' 'Strength' 'Yoga']\n",
      "\n",
      "STEP 3b: Starting Hyperparameter Tuning for Duration/Intensity (GridSearchCV)...\n",
      "This may take a few minutes...\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "‚úÖ Goal Classifier Training Accuracy: 0.9999\n",
      "‚úÖ Goal Classifier Test Accuracy: 0.9835\n",
      "‚úÖ Goal Classifier CV Scores: 0.9850 (+/- 0.0024)\n",
      "‚úÖ Goal Classes: ['Endurance' 'Maintenance' 'Strength' 'Yoga']\n",
      "\n",
      "STEP 3b: Starting Hyperparameter Tuning for Duration/Intensity (GridSearchCV)...\n",
      "This may take a few minutes...\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "\n",
      "‚úÖ Step 3b Complete: Tuning finished in 179.12 seconds.\n",
      "‚úÖ Best Hyperparameters: {'estimator__max_depth': 16, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 4, 'estimator__n_estimators': 220}\n",
      "\n",
      "STEP 4: Evaluating final tuned model on test set...\n",
      "\n",
      "‚úÖ Step 3b Complete: Tuning finished in 179.12 seconds.\n",
      "‚úÖ Best Hyperparameters: {'estimator__max_depth': 16, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 4, 'estimator__n_estimators': 220}\n",
      "\n",
      "STEP 4: Evaluating final tuned model on test set...\n",
      "\n",
      "--- Final Model Performance (on Test Set) ---\n",
      "Overall RMSE: 2.104 | Overall MAE: 1.339 | Overall R2: 0.953\n",
      "\n",
      "Duration (min):\n",
      "  RMSE: 2.93 | MAE: 2.27 | R2: 0.963\n",
      "\n",
      "Intensity (RPE):\n",
      "  RMSE: 0.52 | MAE: 0.40 | R2: 0.943\n",
      "\n",
      "Regression CV Scores: 0.9513 (+/- 0.0011)\n",
      "\n",
      "‚úÖ EXCELLENT: Model shows very good generalization! R2 > 0.78 indicates robust performance.\n",
      "\n",
      "STEP 5: Analyzing Feature Importance...\n",
      "\n",
      "Top 7 Most Important Features:\n",
      "  1. MENTAL_STRESS: 0.3321\n",
      "  2. RHR_BPM: 0.2512\n",
      "  3. CALORIES_IN: 0.2061\n",
      "  4. Weight_kg: 0.0933\n",
      "  5. SORENESS: 0.0461\n",
      "  6. SLEEP_HRS: 0.0166\n",
      "  7. NUTR_CONF_SCORE: 0.0122\n",
      "\n",
      "STEP 6: Saving final model, preprocessor, classifier, and encoder...\n",
      "\n",
      "--- Final Model Performance (on Test Set) ---\n",
      "Overall RMSE: 2.104 | Overall MAE: 1.339 | Overall R2: 0.953\n",
      "\n",
      "Duration (min):\n",
      "  RMSE: 2.93 | MAE: 2.27 | R2: 0.963\n",
      "\n",
      "Intensity (RPE):\n",
      "  RMSE: 0.52 | MAE: 0.40 | R2: 0.943\n",
      "\n",
      "Regression CV Scores: 0.9513 (+/- 0.0011)\n",
      "\n",
      "‚úÖ EXCELLENT: Model shows very good generalization! R2 > 0.78 indicates robust performance.\n",
      "\n",
      "STEP 5: Analyzing Feature Importance...\n",
      "\n",
      "Top 7 Most Important Features:\n",
      "  1. MENTAL_STRESS: 0.3321\n",
      "  2. RHR_BPM: 0.2512\n",
      "  3. CALORIES_IN: 0.2061\n",
      "  4. Weight_kg: 0.0933\n",
      "  5. SORENESS: 0.0461\n",
      "  6. SLEEP_HRS: 0.0166\n",
      "  7. NUTR_CONF_SCORE: 0.0122\n",
      "\n",
      "STEP 6: Saving final model, preprocessor, classifier, and encoder...\n",
      "\n",
      "‚úÖ‚úÖ‚úÖ ENHANCED PIPELINE COMPLETE ‚úÖ‚úÖ‚úÖ\n",
      "‚úÖ Model with advanced weighting trained successfully!\n",
      "‚úÖ 20,000 records with realistic feature correlations generated\n",
      "‚úÖ Goal classes: ['Endurance', 'Maintenance', 'Strength', 'Yoga']\n",
      "‚úÖ All artifacts saved and ready for production\n",
      "\n",
      "Files saved:\n",
      "  ‚Ä¢ mvva_model_v2.joblib\n",
      "  ‚Ä¢ mvva_preprocessor_v2.joblib\n",
      "  ‚Ä¢ mvva_goal_classifier_v2.joblib\n",
      "  ‚Ä¢ mvva_goal_encoder_v2.joblib\n",
      "\n",
      "‚úÖ‚úÖ‚úÖ ENHANCED PIPELINE COMPLETE ‚úÖ‚úÖ‚úÖ\n",
      "‚úÖ Model with advanced weighting trained successfully!\n",
      "‚úÖ 20,000 records with realistic feature correlations generated\n",
      "‚úÖ Goal classes: ['Endurance', 'Maintenance', 'Strength', 'Yoga']\n",
      "‚úÖ All artifacts saved and ready for production\n",
      "\n",
      "Files saved:\n",
      "  ‚Ä¢ mvva_model_v2.joblib\n",
      "  ‚Ä¢ mvva_preprocessor_v2.joblib\n",
      "  ‚Ä¢ mvva_goal_classifier_v2.joblib\n",
      "  ‚Ä¢ mvva_goal_encoder_v2.joblib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedShuffleSplit, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "np.random.seed(42)\n",
    "NUM_RECORDS = 20000  # Increased to 20k for better data diversity and model robustness\n",
    "\n",
    "print(\"--- Iteration 4: ENHANCED Data Generation with Advanced Parameter Weighting ---\")\n",
    "print(\"STEP 1: Generating Enhanced Synthetic Data with Intelligent Weighting...\")\n",
    "\n",
    "# --- 1. Define Input Feature Distributions with Better Real-World Patterns ---\n",
    "# More realistic age distribution (bimodal: young athletes + older fitness enthusiasts)\n",
    "AGE = np.concatenate([\n",
    "    np.random.normal(28, 6, int(NUM_RECORDS * 0.6)).clip(18, 40).astype(int),\n",
    "    np.random.normal(48, 8, int(NUM_RECORDS * 0.4)).clip(40, 70).astype(int)\n",
    "])\n",
    "np.random.shuffle(AGE)\n",
    "AGE = AGE[:NUM_RECORDS]\n",
    "\n",
    "# Sex distribution (slightly more male gym-goers in data)\n",
    "SEX = np.random.choice(['M', 'F'], size=NUM_RECORDS, p=[0.6, 0.4])\n",
    "\n",
    "# Weight follows BMI-realistic distribution\n",
    "WEIGHT_KG = np.random.normal(78, 14, size=NUM_RECORDS).clip(45, 130).round(1)\n",
    "\n",
    "# Sleep: realistic with some chronically sleep-deprived individuals\n",
    "SLEEP_HRS = np.concatenate([\n",
    "    np.random.normal(7.3, 0.8, int(NUM_RECORDS * 0.75)),\n",
    "    np.random.normal(5.5, 0.6, int(NUM_RECORDS * 0.25))\n",
    "]).clip(4.0, 10.0).round(1)\n",
    "np.random.shuffle(SLEEP_HRS)\n",
    "\n",
    "# RHR correlates somewhat with fitness level (lower is generally better)\n",
    "RHR_BASE = 62 + (WEIGHT_KG - 75) * 0.15  # Heavier people tend to have higher RHR\n",
    "RHR_BPM = (RHR_BASE + np.random.normal(0, 6, size=NUM_RECORDS)).clip(45, 95).round(0)\n",
    "\n",
    "# Soreness distribution: skewed toward low soreness (most people don't report high soreness)\n",
    "SORENESS = np.random.choice([1, 2, 3, 4, 5], size=NUM_RECORDS, p=[0.35, 0.30, 0.20, 0.10, 0.05])\n",
    "\n",
    "# Mental stress: slightly elevated (realistic for modern population)\n",
    "MENTAL_STRESS = np.random.choice([1, 2, 3, 4, 5], size=NUM_RECORDS, p=[0.20, 0.30, 0.30, 0.15, 0.05])\n",
    "\n",
    "# Calories: correlate with weight and gender (heavier people eat more)\n",
    "CALORIES = (2100 + (WEIGHT_KG - 75) * 8 + (SEX == 'M') * 200 + \n",
    "            np.random.normal(0, 300, size=NUM_RECORDS)).clip(1200, 4500).round(0)\n",
    "\n",
    "# Protein: correlate with fitness goal (assume people who work out eat more protein)\n",
    "PROTEIN_G = (90 + WEIGHT_KG * 0.8 + np.random.normal(0, 25, size=NUM_RECORDS)).clip(40, 250).round(0)\n",
    "\n",
    "# Carbs: correlate with activity (higher carbs for high carb days)\n",
    "CARBS_G = (200 + CALORIES * 0.35 / 4 + np.random.normal(0, 50, size=NUM_RECORDS)).clip(80, 550).round(0)\n",
    "\n",
    "# Nutrition confidence: distribution reflecting real world (high confidence most common)\n",
    "NUTR_CONF_SCORE = np.random.choice([1.0, 0.75, 0.5], size=NUM_RECORDS, p=[0.70, 0.20, 0.10])\n",
    "\n",
    "# --- 2. Assemble DataFrame ---\n",
    "df = pd.DataFrame({\n",
    "    'Age': AGE, 'Sex': SEX, 'Weight_kg': WEIGHT_KG,\n",
    "    'SLEEP_HRS': SLEEP_HRS, 'RHR_BPM': RHR_BPM, 'SORENESS': SORENESS,\n",
    "    'MENTAL_STRESS': MENTAL_STRESS, 'CALORIES_IN': CALORIES,\n",
    "    'PROTEIN_G': PROTEIN_G, 'CARBS_G': CARBS_G, 'NUTR_CONF_SCORE': NUTR_CONF_SCORE\n",
    "})\n",
    "\n",
    "print(f\"‚úÖ Generated {NUM_RECORDS} records with realistic feature correlations\")\n",
    "print(f\"   Mean Age: {AGE.mean():.1f} | Mean Weight: {WEIGHT_KG.mean():.1f}kg | Mean Sleep: {SLEEP_HRS.mean():.1f}h\")\n",
    "\n",
    "# --- 3. ADVANCED Rule-Based Labeling with Intelligent Parameter Weighting ---\n",
    "base_duration = 45.0\n",
    "base_intensity_rpe = 6.0\n",
    "\n",
    "# --- IMPROVED Modifiers with Graduated Weighting ---\n",
    "\n",
    "# Sleep modifier: Non-linear response (bigger penalty for really poor sleep)\n",
    "sleep_modifier = np.ones(NUM_RECORDS)\n",
    "sleep_modifier[df['SLEEP_HRS'] < 4.5] = 0.5      # Severe sleep deprivation\n",
    "sleep_modifier[(df['SLEEP_HRS'] >= 4.5) & (df['SLEEP_HRS'] < 5.5)] = 0.65\n",
    "sleep_modifier[(df['SLEEP_HRS'] >= 5.5) & (df['SLEEP_HRS'] < 6.5)] = 0.85\n",
    "sleep_modifier[(df['SLEEP_HRS'] >= 7.0) & (df['SLEEP_HRS'] < 8.0)] = 1.05\n",
    "sleep_modifier[df['SLEEP_HRS'] >= 8.0] = 1.15   # Well-rested\n",
    "\n",
    "# Soreness modifier: Progressive recovery (5 is near-complete rest)\n",
    "soreness_modifier = np.where(df['SORENESS'] == 5, 0.35,\n",
    "                    np.where(df['SORENESS'] == 4, 0.55,\n",
    "                    np.where(df['SORENESS'] == 3, 0.80,\n",
    "                    np.where(df['SORENESS'] == 2, 0.95, 1.0))))  # 1 = full go\n",
    "\n",
    "# RHR-based readiness: Elevated RHR suggests incomplete recovery or illness\n",
    "rhr_baseline = 62\n",
    "rhr_modifier = 1.0 - (df['RHR_BPM'] - rhr_baseline) * 0.015  # Each 5 bpm above baseline = ~7.5% reduction\n",
    "rhr_modifier = np.clip(rhr_modifier, 0.7, 1.15)\n",
    "\n",
    "# Carbs modifier: More nuanced - mid-range carbs are optimal\n",
    "carbs_modifier = np.ones(NUM_RECORDS)\n",
    "carbs_modifier[df['CARBS_G'] < 120] = 0.75       # Very low carbs = weak performance\n",
    "carbs_modifier[(df['CARBS_G'] >= 120) & (df['CARBS_G'] < 180)] = 0.90\n",
    "carbs_modifier[(df['CARBS_G'] >= 180) & (df['CARBS_G'] < 350)] = 1.0   # Optimal range\n",
    "carbs_modifier[(df['CARBS_G'] >= 350) & (df['CARBS_G'] < 450)] = 0.95  # Slightly too much\n",
    "carbs_modifier[df['CARBS_G'] >= 450] = 0.85     # Way too many carbs = lethargy\n",
    "\n",
    "# Protein modifier: More protein = more ready for strength\n",
    "protein_modifier = np.clip(df['PROTEIN_G'] / 120, 0.8, 1.15)\n",
    "\n",
    "# Stress modifier: Nuanced - some stress is good (eustress), too much is bad\n",
    "stress_modifier = np.ones(NUM_RECORDS)\n",
    "stress_modifier[df['MENTAL_STRESS'] == 1] = 1.0   # Low stress = good\n",
    "stress_modifier[df['MENTAL_STRESS'] == 2] = 1.05  # Slightly elevated = some motivation\n",
    "stress_modifier[df['MENTAL_STRESS'] == 3] = 0.95  # Moderate stress = slightly reduced capacity\n",
    "stress_modifier[df['MENTAL_STRESS'] == 4] = 0.75  # High stress = significant reduction\n",
    "stress_modifier[df['MENTAL_STRESS'] == 5] = 0.5   # Severe stress = rest recommended\n",
    "\n",
    "# Gender modifier: Males typically have higher baseline intensity/duration\n",
    "gender_modifier = np.where(df['Sex'] == 'M', 1.10, 1.0)\n",
    "\n",
    "# Age modifier: Graduated, not linear\n",
    "age_modifier = np.ones(NUM_RECORDS)\n",
    "age_modifier[df['Age'] < 25] = 1.15   # Young athletes peak\n",
    "age_modifier[(df['Age'] >= 25) & (df['Age'] < 35)] = 1.05\n",
    "age_modifier[(df['Age'] >= 35) & (df['Age'] < 45)] = 1.0\n",
    "age_modifier[(df['Age'] >= 45) & (df['Age'] < 55)] = 0.90\n",
    "age_modifier[(df['Age'] >= 55) & (df['Age'] < 65)] = 0.75\n",
    "age_modifier[df['Age'] >= 65] = 0.60\n",
    "\n",
    "# Weight-based modifier: Heavier people may fatigue faster but have strength advantage\n",
    "weight_modifier = 1.0 + ((df['Weight_kg'] - 75) * 0.003)  # Reduced sensitivity\n",
    "weight_modifier = np.clip(weight_modifier, 0.85, 1.15)\n",
    "\n",
    "# Nutrition confidence: Low confidence = conservative estimates\n",
    "confidence_modifier = df['NUTR_CONF_SCORE']  # Ranges 0.5-1.0\n",
    "confidence_modifier = np.clip(confidence_modifier, 0.75, 1.0)  # Don't penalize too heavily\n",
    "\n",
    "print(f\"‚úÖ Parameter modifiers calculated with advanced weighting\")\n",
    "\n",
    "# *** GOAL PREDICTION with Enhanced Weighting ***\n",
    "# More sophisticated factor scoring based on real exercise science\n",
    "\n",
    "strength_factors = (\n",
    "    (df['SLEEP_HRS'] >= 7.5) * 3.0 +           # Sleep crucial for strength gains\n",
    "    (df['SORENESS'] <= 2) * 2.5 +               # Low soreness = good recovery\n",
    "    (df['PROTEIN_G'] >= 130) * 2.0 +            # High protein for muscle building\n",
    "    (df['CARBS_G'] >= 220) * 1.5 +              # Adequate carbs for workout fuel\n",
    "    (df['MENTAL_STRESS'] <= 2) * 1.5 +          # Low stress = better focus\n",
    "    (df['Age'] <= 35) * 1.0 +                   # Peak athletic age\n",
    "    (df['RHR_BPM'] < 65) * 1.0                  # Lower RHR = good recovery\n",
    ")\n",
    "\n",
    "endurance_factors = (\n",
    "    (df['CARBS_G'] >= 300) * 3.5 +              # Carbs are king for endurance\n",
    "    (df['SLEEP_HRS'] >= 6.5) * 2.0 +            # Good sleep for aerobic adaptation\n",
    "    (df['SORENESS'] <= 3) * 1.5 +               # Manageable soreness\n",
    "    (df['Age'] <= 50) * 1.5 +                   # Endurance peaks earlier than strength\n",
    "    (df['PROTEIN_G'] >= 100) * 1.0              # Some protein for recovery\n",
    ")\n",
    "\n",
    "maintenance_factors = (\n",
    "    (df['SORENESS'] >= 4) * 4.0 +               # HIGH WEIGHT: high soreness needs recovery\n",
    "    (df['SLEEP_HRS'] < 6.0) * 3.5 +             # Poor sleep = recovery day\n",
    "    (df['MENTAL_STRESS'] >= 4) * 3.0 +          # High stress = lighter activity\n",
    "    (df['Age'] >= 45) * 2.0 +                   # Age-appropriate maintenance\n",
    "    (df['RHR_BPM'] > 75) * 2.0 +                # Elevated RHR = not recovered\n",
    "    (df['CARBS_G'] < 150) * 1.5                 # Low carbs = low fuel\n",
    ")\n",
    "\n",
    "# Yoga factors with high priority for mental recovery\n",
    "yoga_factors = (\n",
    "    (df['MENTAL_STRESS'] >= 4) * 6.0 +          # Mental health first\n",
    "    (df['SORENESS'] >= 4) * 3.0 +               # Also great for physical recovery\n",
    "    (df['RHR_BPM'] > 75) * 2.5 +                # High RHR = stressed/unrecovered\n",
    "    (df['SLEEP_HRS'] < 6.5) * 2.0 +             # Poor sleep pairs with yoga\n",
    "    (df['Age'] >= 50) * 1.0                     # Good for older athletes\n",
    ")\n",
    "\n",
    "# Determine goal based on highest weighted score\n",
    "df['GOAL'] = 'Maintenance'  # Default\n",
    "\n",
    "# Vectorized goal assignment for efficiency\n",
    "strength_score = strength_factors.values\n",
    "endurance_score = endurance_factors.values\n",
    "maintenance_score = maintenance_factors.values\n",
    "yoga_score = yoga_factors.values\n",
    "\n",
    "goal_matrix = np.column_stack([strength_score, endurance_score, maintenance_score, yoga_score])\n",
    "goal_labels = ['Strength', 'Endurance', 'Maintenance', 'Yoga']\n",
    "df['GOAL'] = [goal_labels[np.argmax(row)] for row in goal_matrix]\n",
    "\n",
    "print(f\"\\n‚úÖ Goal Distribution (with advanced weighting):\")\n",
    "print(df['GOAL'].value_counts())\n",
    "print(f\"   {df['GOAL'].value_counts().to_dict()}\")\n",
    "\n",
    "# Goal-specific modifiers with better differentiation\n",
    "goal_duration_modifier = np.select(\n",
    "    [df['GOAL'] == 'Endurance', df['GOAL'] == 'Strength', df['GOAL'] == 'Yoga', df['GOAL'] == 'Maintenance'],\n",
    "    [1.20, 1.05, 0.65, 0.75],  # Endurance: longer, Yoga: very short\n",
    "    default=1.0\n",
    ")\n",
    "\n",
    "goal_intensity_modifier = np.select(\n",
    "    [df['GOAL'] == 'Endurance', df['GOAL'] == 'Strength', df['GOAL'] == 'Yoga', df['GOAL'] == 'Maintenance'],\n",
    "    [0.85, 1.15, 0.35, 0.70],  # Strength: highest intensity, Yoga: lowest\n",
    "    default=1.0\n",
    ")\n",
    "\n",
    "# Calculate final predictions with ALL modifiers\n",
    "# Duration and intensity are both affected by readiness factors\n",
    "combined_readiness = (sleep_modifier * soreness_modifier * rhr_modifier * \n",
    "                      stress_modifier * confidence_modifier)\n",
    "\n",
    "df['Optimal_Intensity_RPE'] = (base_intensity_rpe * \n",
    "                                combined_readiness *\n",
    "                                gender_modifier * \n",
    "                                age_modifier * \n",
    "                                protein_modifier *\n",
    "                                carbs_modifier *\n",
    "                                goal_intensity_modifier * \n",
    "                                weight_modifier)\n",
    "\n",
    "df['Optimal_Duration_Min'] = (base_duration * \n",
    "                              sleep_modifier * \n",
    "                              soreness_modifier * \n",
    "                              rhr_modifier *\n",
    "                              stress_modifier * \n",
    "                              gender_modifier * \n",
    "                              age_modifier * \n",
    "                              goal_duration_modifier * \n",
    "                              weight_modifier)\n",
    "\n",
    "# Clamp outputs to valid ranges\n",
    "df['Optimal_Duration_Min'] = df['Optimal_Duration_Min'].clip(12, 120).round(0)\n",
    "df['Optimal_Intensity_RPE'] = df['Optimal_Intensity_RPE'].clip(1.5, 9.5).round(1)\n",
    "\n",
    "print(f\"\\n‚úÖ Step 1 Complete: Enhanced data with intelligent parameter weighting generated.\")\n",
    "print(f\"   Duration range: {df['Optimal_Duration_Min'].min():.0f}-{df['Optimal_Duration_Min'].max():.0f} min\")\n",
    "print(f\"   Intensity range: {df['Optimal_Intensity_RPE'].min():.1f}-{df['Optimal_Intensity_RPE'].max():.1f} RPE\")\n",
    "\n",
    "# --- 4. Feature Engineering (Preprocessing) with StandardScaler ---\n",
    "print(\"\\nSTEP 2: Preprocessing features (Encoding + Scaling)...\")\n",
    "\n",
    "TARGETS = ['Optimal_Duration_Min', 'Optimal_Intensity_RPE', 'GOAL']\n",
    "X = df.drop(columns=TARGETS)\n",
    "Y = df[['Optimal_Duration_Min', 'Optimal_Intensity_RPE']]\n",
    "Y_goal = df['GOAL']\n",
    "\n",
    "categorical_features = ['Sex']\n",
    "numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# Enhanced preprocessor with StandardScaler for numerical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),\n",
    "        ('num', StandardScaler(), numerical_features)  # Added scaling for better model performance\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "Y_values = Y.values\n",
    "\n",
    "# IMPROVED: Use StratifiedShuffleSplit to ensure balanced goal distribution in train/test\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "goal_encoder = LabelEncoder()\n",
    "Y_goal_encoded = goal_encoder.fit_transform(Y_goal)\n",
    "\n",
    "# Stratified split ensures each set has similar goal distribution\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, test_idx = next(sss.split(X_processed, Y_goal_encoded))\n",
    "\n",
    "X_train = X_processed[train_idx]\n",
    "X_test = X_processed[test_idx]\n",
    "Y_train = Y_values[train_idx]\n",
    "Y_test = Y_values[test_idx]\n",
    "Y_goal_train = Y_goal_encoded[train_idx]\n",
    "Y_goal_test = Y_goal_encoded[test_idx]\n",
    "\n",
    "print(f\"‚úÖ Step 2 Complete: Train/Test split with stratification (train: {len(train_idx)}, test: {len(test_idx)})\")\n",
    "\n",
    "# --- 5. Train Goal Classifier with Cross-Validation ---\n",
    "print(\"\\nSTEP 3a: Training Goal Classifier with Cross-Validation...\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# RandomForest often generalizes better than XGBoost on synthetic data\n",
    "goal_classifier = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=15,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    class_weight='balanced'  # Handle imbalanced classes\n",
    ")\n",
    "\n",
    "goal_classifier.fit(X_train, Y_goal_train)\n",
    "goal_pred_train = goal_classifier.predict(X_train)\n",
    "goal_pred_test = goal_classifier.predict(X_test)\n",
    "goal_accuracy_train = (goal_pred_train == Y_goal_train).mean()\n",
    "goal_accuracy_test = (goal_pred_test == Y_goal_test).mean()\n",
    "\n",
    "# Cross-validation score\n",
    "cv_scores = cross_val_score(goal_classifier, X_train, Y_goal_train, cv=5, scoring='accuracy')\n",
    "\n",
    "print(f\"‚úÖ Goal Classifier Training Accuracy: {goal_accuracy_train:.4f}\")\n",
    "print(f\"‚úÖ Goal Classifier Test Accuracy: {goal_accuracy_test:.4f}\")\n",
    "print(f\"‚úÖ Goal Classifier CV Scores: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
    "print(f\"‚úÖ Goal Classes: {goal_encoder.classes_}\")\n",
    "\n",
    "# --- 6. Train Duration/Intensity Regressor ---\n",
    "print(\"\\nSTEP 3b: Starting Hyperparameter Tuning for Duration/Intensity (GridSearchCV)...\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Use RandomForestRegressor for better generalization on synthetic data\n",
    "# XGBoost can overfit on synthetic data\n",
    "base_rf = RandomForestRegressor(\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    max_features='sqrt'  # Reduce feature space per split for stability\n",
    ")\n",
    "\n",
    "multi_model = MultiOutputRegressor(base_rf)\n",
    "\n",
    "# Focused parameter grid for RandomForest with improved ranges\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [180, 220],\n",
    "    'estimator__max_depth': [12, 16],\n",
    "    'estimator__min_samples_split': [4, 6],\n",
    "    'estimator__min_samples_leaf': [2, 3]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=multi_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\n‚úÖ Step 3b Complete: Tuning finished in {end_time - start_time:.2f} seconds.\")\n",
    "print(f\"‚úÖ Best Hyperparameters: {grid_search.best_params_}\")\n",
    "\n",
    "# --- 7. Evaluate the BEST Model with per-output metrics ---\n",
    "print(\"\\nSTEP 4: Evaluating final tuned model on test set...\")\n",
    "\n",
    "best_mvva_model = grid_search.best_estimator_\n",
    "Y_pred = best_mvva_model.predict(X_test)\n",
    "\n",
    "# Per-output metrics for better debugging\n",
    "rmse_duration = np.sqrt(mean_squared_error(Y_test[:, 0], Y_pred[:, 0]))\n",
    "rmse_intensity = np.sqrt(mean_squared_error(Y_test[:, 1], Y_pred[:, 1]))\n",
    "mae_duration = mean_absolute_error(Y_test[:, 0], Y_pred[:, 0])\n",
    "mae_intensity = mean_absolute_error(Y_test[:, 1], Y_pred[:, 1])\n",
    "r2_duration = r2_score(Y_test[:, 0], Y_pred[:, 0])\n",
    "r2_intensity = r2_score(Y_test[:, 1], Y_pred[:, 1])\n",
    "\n",
    "rmse_overall = np.sqrt(mean_squared_error(Y_test, Y_pred))\n",
    "mae_overall = mean_absolute_error(Y_test, Y_pred)\n",
    "r2_overall = r2_score(Y_test, Y_pred)\n",
    "\n",
    "# Cross-validation scores for regression\n",
    "cv_scores_reg = cross_val_score(grid_search.best_estimator_, X_train, Y_train, cv=5, scoring='r2')\n",
    "\n",
    "print(\"\\n--- Final Model Performance (on Test Set) ---\")\n",
    "print(f\"Overall RMSE: {rmse_overall:.3f} | Overall MAE: {mae_overall:.3f} | Overall R2: {r2_overall:.3f}\")\n",
    "print(f\"\\nDuration (min):\")\n",
    "print(f\"  RMSE: {rmse_duration:.2f} | MAE: {mae_duration:.2f} | R2: {r2_duration:.3f}\")\n",
    "print(f\"\\nIntensity (RPE):\")\n",
    "print(f\"  RMSE: {rmse_intensity:.2f} | MAE: {mae_intensity:.2f} | R2: {r2_intensity:.3f}\")\n",
    "print(f\"\\nRegression CV Scores: {cv_scores_reg.mean():.4f} (+/- {cv_scores_reg.std():.4f})\")\n",
    "\n",
    "if r2_overall > 0.78:\n",
    "    print(\"\\n‚úÖ EXCELLENT: Model shows very good generalization! R2 > 0.78 indicates robust performance.\")\n",
    "elif r2_overall > 0.75:\n",
    "    print(\"\\n‚úÖ GOOD: Model shows good generalization! R2 > 0.75 indicates solid performance.\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è WARNING: R2 = {r2_overall:.3f}. Model may need more data or different features.\")\n",
    "\n",
    "# --- 8. Feature Importance Analysis (for transparency) ---\n",
    "print(\"\\nSTEP 5: Analyzing Feature Importance...\")\n",
    "feature_names = []\n",
    "for name, transformer, columns in preprocessor.transformers_:\n",
    "    if name == 'cat':\n",
    "        feature_names.extend([f\"{col}_encoded\" for col in columns])\n",
    "    else:\n",
    "        feature_names.extend(columns)\n",
    "\n",
    "# Get feature importances from the best RandomForest estimator\n",
    "if hasattr(best_mvva_model.estimators_[0], 'feature_importances_'):\n",
    "    importances = best_mvva_model.estimators_[0].feature_importances_\n",
    "    top_7_idx = np.argsort(importances)[-7:][::-1]\n",
    "    print(\"\\nTop 7 Most Important Features:\")\n",
    "    for i, idx in enumerate(top_7_idx):\n",
    "        print(f\"  {i+1}. {feature_names[idx]}: {importances[idx]:.4f}\")\n",
    "\n",
    "# --- 9. Save ALL Artifacts ---\n",
    "print(\"\\nSTEP 6: Saving final model, preprocessor, classifier, and encoder...\")\n",
    "\n",
    "MODEL_FILENAME_V2 = 'mvva_model_v2.joblib'\n",
    "PREPROCESSOR_FILENAME_V2 = 'mvva_preprocessor_v2.joblib'\n",
    "GOAL_CLASSIFIER_FILENAME_V2 = 'mvva_goal_classifier_v2.joblib'\n",
    "GOAL_ENCODER_FILENAME_V2 = 'mvva_goal_encoder_v2.joblib'\n",
    "\n",
    "joblib.dump(best_mvva_model, MODEL_FILENAME_V2)\n",
    "joblib.dump(preprocessor, PREPROCESSOR_FILENAME_V2)\n",
    "joblib.dump(goal_classifier, GOAL_CLASSIFIER_FILENAME_V2)\n",
    "joblib.dump(goal_encoder, GOAL_ENCODER_FILENAME_V2)\n",
    "\n",
    "print(f\"\\n‚úÖ‚úÖ‚úÖ ENHANCED PIPELINE COMPLETE ‚úÖ‚úÖ‚úÖ\")\n",
    "print(f\"‚úÖ Model with advanced weighting trained successfully!\")\n",
    "print(f\"‚úÖ 20,000 records with realistic feature correlations generated\")\n",
    "print(f\"‚úÖ Goal classes: {list(goal_encoder.classes_)}\")\n",
    "print(f\"‚úÖ All artifacts saved and ready for production\")\n",
    "print(f\"\\nFiles saved:\")\n",
    "print(f\"  ‚Ä¢ {MODEL_FILENAME_V2}\")\n",
    "print(f\"  ‚Ä¢ {PREPROCESSOR_FILENAME_V2}\")\n",
    "print(f\"  ‚Ä¢ {GOAL_CLASSIFIER_FILENAME_V2}\")\n",
    "print(f\"  ‚Ä¢ {GOAL_ENCODER_FILENAME_V2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5b2b0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "OPTIONAL STEP: Loading User Feedback for Continuous Learning...\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Found feedback file: feedback_history.csv\n",
      "‚úÖ Loaded 4 feedback records from users\n",
      "\n",
      "‚úÖ Converted 4 feedback records to training data\n",
      "   Adjusted durations: 56.0 min (avg)\n",
      "   Adjusted intensities: 4.9 RPE (avg)\n",
      "\n",
      "‚úÖ Combined datasets:\n",
      "   Original synthetic: 20000 records\n",
      "   User feedback (weighted): 8 records\n",
      "   Total training data: 20008 records\n",
      "\n",
      "‚úÖ Using combined data with user feedback for model training!\n",
      "   This makes the model adapt to user preferences and actual performance\n",
      "\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Loaded 4 feedback records from users\n",
      "\n",
      "‚úÖ Converted 4 feedback records to training data\n",
      "   Adjusted durations: 56.0 min (avg)\n",
      "   Adjusted intensities: 4.9 RPE (avg)\n",
      "\n",
      "‚úÖ Combined datasets:\n",
      "   Original synthetic: 20000 records\n",
      "   User feedback (weighted): 8 records\n",
      "   Total training data: 20008 records\n",
      "\n",
      "‚úÖ Using combined data with user feedback for model training!\n",
      "   This makes the model adapt to user preferences and actual performance\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- BONUS STEP: CONTINUOUS LEARNING FROM USER FEEDBACK ---\n",
    "# Load user feedback if available and incorporate into training data\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OPTIONAL STEP: Loading User Feedback for Continuous Learning...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "feedback_file = 'feedback_history.csv'\n",
    "\n",
    "if os.path.exists(feedback_file):\n",
    "    print(f\"\\n‚úÖ Found feedback file: {feedback_file}\")\n",
    "    feedback_df = pd.read_csv(feedback_file)\n",
    "    print(f\"‚úÖ Loaded {len(feedback_df)} feedback records from users\")\n",
    "    \n",
    "    # Convert feedback to synthetic training data\n",
    "    # If user completed more than 90%, they could have done more\n",
    "    # If user completed 50-70%, difficulty was right\n",
    "    # If user completed <50%, they should have done less\n",
    "    \n",
    "    synthetic_feedback_data = []\n",
    "    \n",
    "    for idx, row in feedback_df.iterrows():\n",
    "        # Extract original input features\n",
    "        feedback_record = {\n",
    "            'Age': row['age'],\n",
    "            'Sex': row['sex'],\n",
    "            'Weight_kg': row['weight_kg'],\n",
    "            'SLEEP_HRS': row['sleep_hrs'],\n",
    "            'RHR_BPM': row['rhr_bpm'],\n",
    "            'SORENESS': row['soreness_before'],\n",
    "            'MENTAL_STRESS': row['mental_stress'],\n",
    "            'CALORIES_IN': row['calories_in'],\n",
    "            'PROTEIN_G': row['protein_g'],\n",
    "            'CARBS_G': row['carbs_g'],\n",
    "            'NUTR_CONF_SCORE': 0.9,  # User-provided feedback is high confidence\n",
    "            'GOAL': row['predicted_goal']\n",
    "        }\n",
    "        \n",
    "        # Adjust targets based on user satisfaction\n",
    "        completion_pct = row['workout_completion_pct']\n",
    "        actual_intensity = row['actual_intensity']\n",
    "        recovery_feeling = row['recovery_feeling']\n",
    "        \n",
    "        # Calculate adjustment factors based on feedback\n",
    "        # If user completed <50%, they were overestimated - reduce duration/intensity\n",
    "        # If user completed >90%, they could do more - increase duration/intensity\n",
    "        # If 50-80%, it was about right\n",
    "        \n",
    "        if completion_pct >= 90 and recovery_feeling >= 4:\n",
    "            # Could have done more - increase both\n",
    "            duration_adjustment = 1.10\n",
    "            intensity_adjustment = 1.08\n",
    "        elif completion_pct >= 80 and completion_pct < 90:\n",
    "            # Pretty good but could push slightly more\n",
    "            duration_adjustment = 1.05\n",
    "            intensity_adjustment = 1.03\n",
    "        elif completion_pct >= 70 and completion_pct < 80:\n",
    "            # About right\n",
    "            duration_adjustment = 1.0\n",
    "            intensity_adjustment = 1.0\n",
    "        elif completion_pct >= 50 and completion_pct < 70:\n",
    "            # Slightly overestimated\n",
    "            duration_adjustment = 0.95\n",
    "            intensity_adjustment = 0.95\n",
    "        else:  # < 50%\n",
    "            # Significantly overestimated\n",
    "            duration_adjustment = 0.85\n",
    "            intensity_adjustment = 0.85\n",
    "        \n",
    "        # Apply recovery feeling adjustment\n",
    "        if recovery_feeling == 1:  # Exhausted\n",
    "            duration_adjustment *= 0.90\n",
    "            intensity_adjustment *= 0.90\n",
    "        elif recovery_feeling == 5:  # Fully refreshed\n",
    "            duration_adjustment *= 1.05\n",
    "            intensity_adjustment *= 1.05\n",
    "        \n",
    "        # Set targets with adjustments\n",
    "        feedback_record['Optimal_Duration_Min'] = row['recommended_duration'] * duration_adjustment\n",
    "        feedback_record['Optimal_Intensity_RPE'] = row['recommended_intensity'] * intensity_adjustment\n",
    "        \n",
    "        synthetic_feedback_data.append(feedback_record)\n",
    "    \n",
    "    # Create feedback dataframe\n",
    "    feedback_synthetic_df = pd.DataFrame(synthetic_feedback_data)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Converted {len(feedback_synthetic_df)} feedback records to training data\")\n",
    "    print(f\"   Adjusted durations: {feedback_synthetic_df['Optimal_Duration_Min'].mean():.1f} min (avg)\")\n",
    "    print(f\"   Adjusted intensities: {feedback_synthetic_df['Optimal_Intensity_RPE'].mean():.1f} RPE (avg)\")\n",
    "    \n",
    "    # Combine with synthetic data (feedback gets higher weight)\n",
    "    # Use 70% synthetic, 30% feedback to avoid overfitting to feedback\n",
    "    num_synthetic = len(df)\n",
    "    num_feedback = len(feedback_synthetic_df)\n",
    "    \n",
    "    # Weight feedback data to give it more importance\n",
    "    feedback_weighted = pd.concat([feedback_synthetic_df] * 2, ignore_index=True)  # Double weight\n",
    "    \n",
    "    # Combine datasets\n",
    "    df_combined = pd.concat([df, feedback_weighted], ignore_index=True)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Combined datasets:\")\n",
    "    print(f\"   Original synthetic: {num_synthetic} records\")\n",
    "    print(f\"   User feedback (weighted): {len(feedback_weighted)} records\")\n",
    "    print(f\"   Total training data: {len(df_combined)} records\")\n",
    "    \n",
    "    # Use combined data for subsequent training\n",
    "    df = df_combined\n",
    "    print(f\"\\n‚úÖ Using combined data with user feedback for model training!\")\n",
    "    print(f\"   This makes the model adapt to user preferences and actual performance\")\n",
    "    \n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è No feedback file found. Using only synthetic data.\")\n",
    "    print(f\"   Feedback will be available after first few users submit post-workout feedback.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aa42389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FEEDBACK ANALYTICS: How is the model adapting to user preferences?\n",
      "================================================================================\n",
      "\n",
      "üìä FEEDBACK ANALYSIS (4 submissions):\n",
      "\n",
      "1. WORKOUT COMPLETION:\n",
      "   Average: 100.0% (¬±0.0%)\n",
      "   High achievers (‚â•90%): 4 users\n",
      "   Struggled (<50%): 0 users\n",
      "\n",
      "2. INTENSITY ACCURACY:\n",
      "   Average Actual/Recommended: 0.88x\n",
      "   Target range: 0.90-1.10 (user can do 90-110% of recommendation)\n",
      "   ‚ö†Ô∏è Model is overestimating intensity - recommend DECREASING\n",
      "\n",
      "3. POST-WORKOUT RECOVERY:\n",
      "   Average recovery feeling: 3.5/5\n",
      "   Exhausted (1/5): 0 users\n",
      "   Refreshed (5/5): 0 users\n",
      "\n",
      "4. SATISFACTION & REPEATABILITY:\n",
      "   Would repeat workout: 1 users said 'definitely yes'\n",
      "   Uncertain/No: 0 users\n",
      "\n",
      "üí° MODEL ADAPTATION INSIGHTS:\n",
      "   ‚úÖ The combined model learns from 4 real user workouts\n",
      "   ‚úÖ Next retrain will be SMARTER based on actual performance data\n",
      "   ‚úÖ Recommendations are optimized for YOUR audience's capabilities\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# --- FEEDBACK ANALYTICS & MODEL ADAPTATION ANALYSIS ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEEDBACK ANALYTICS: How is the model adapting to user preferences?\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if os.path.exists('feedback_history.csv'):\n",
    "    feedback_df = pd.read_csv('feedback_history.csv')\n",
    "    \n",
    "    print(f\"\\nüìä FEEDBACK ANALYSIS ({len(feedback_df)} submissions):\")\n",
    "    \n",
    "    # Completion patterns\n",
    "    avg_completion = feedback_df['workout_completion_pct'].mean()\n",
    "    completion_std = feedback_df['workout_completion_pct'].std()\n",
    "    print(f\"\\n1. WORKOUT COMPLETION:\")\n",
    "    print(f\"   Average: {avg_completion:.1f}% (¬±{completion_std:.1f}%)\")\n",
    "    \n",
    "    high_completion = (feedback_df['workout_completion_pct'] >= 90).sum()\n",
    "    low_completion = (feedback_df['workout_completion_pct'] < 50).sum()\n",
    "    print(f\"   High achievers (‚â•90%): {high_completion} users\")\n",
    "    print(f\"   Struggled (<50%): {low_completion} users\")\n",
    "    \n",
    "    # Intensity accuracy\n",
    "    actual_vs_recommended = feedback_df['actual_intensity'] / feedback_df['recommended_intensity']\n",
    "    print(f\"\\n2. INTENSITY ACCURACY:\")\n",
    "    print(f\"   Average Actual/Recommended: {actual_vs_recommended.mean():.2f}x\")\n",
    "    print(f\"   Target range: 0.90-1.10 (user can do 90-110% of recommendation)\")\n",
    "    \n",
    "    if actual_vs_recommended.mean() < 0.90:\n",
    "        print(f\"   ‚ö†Ô∏è Model is overestimating intensity - recommend DECREASING\")\n",
    "    elif actual_vs_recommended.mean() > 1.10:\n",
    "        print(f\"   ‚úÖ Model is underestimating - could push harder\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Intensity estimates are well-calibrated\")\n",
    "    \n",
    "    # Recovery patterns\n",
    "    avg_recovery = feedback_df['recovery_feeling'].mean()\n",
    "    print(f\"\\n3. POST-WORKOUT RECOVERY:\")\n",
    "    print(f\"   Average recovery feeling: {avg_recovery:.1f}/5\")\n",
    "    \n",
    "    exhausted = (feedback_df['recovery_feeling'] == 1).sum()\n",
    "    refreshed = (feedback_df['recovery_feeling'] == 5).sum()\n",
    "    print(f\"   Exhausted (1/5): {exhausted} users\")\n",
    "    print(f\"   Refreshed (5/5): {refreshed} users\")\n",
    "    \n",
    "    if avg_recovery < 2.5:\n",
    "        print(f\"   ‚ö†Ô∏è Users are too exhausted - recommend REDUCING duration/intensity\")\n",
    "    elif avg_recovery > 4:\n",
    "        print(f\"   ‚úÖ Good balance - users can handle current recommendations\")\n",
    "    \n",
    "    # Satisfaction patterns\n",
    "    very_satisfied = (feedback_df['would_repeat'] == 'Yes, definitely! ‚úÖ').sum()\n",
    "    not_satisfied = (feedback_df['would_repeat'].isin(['Maybe ü§î', 'No üëé'])).sum()\n",
    "    \n",
    "    print(f\"\\n4. SATISFACTION & REPEATABILITY:\")\n",
    "    print(f\"   Would repeat workout: {very_satisfied} users said 'definitely yes'\")\n",
    "    print(f\"   Uncertain/No: {not_satisfied} users\")\n",
    "    \n",
    "    # Feature-based patterns (if enough data)\n",
    "    if len(feedback_df) >= 10:\n",
    "        print(f\"\\n5. PATTERNS BY USER CHARACTERISTICS:\")\n",
    "        \n",
    "        # By age groups\n",
    "        young = feedback_df[feedback_df['age'] < 35]['workout_completion_pct'].mean()\n",
    "        old = feedback_df[feedback_df['age'] >= 45]['workout_completion_pct'].mean()\n",
    "        print(f\"   Younger users (<35): {young:.1f}% completion\")\n",
    "        print(f\"   Older users (‚â•45): {old:.1f}% completion\")\n",
    "        \n",
    "        # By stress levels\n",
    "        low_stress = feedback_df[feedback_df['mental_stress'] <= 2]['workout_completion_pct'].mean()\n",
    "        high_stress = feedback_df[feedback_df['mental_stress'] >= 4]['workout_completion_pct'].mean()\n",
    "        print(f\"   Low stress users: {low_stress:.1f}% completion\")\n",
    "        print(f\"   High stress users: {high_stress:.1f}% completion\")\n",
    "        \n",
    "        # By sleep quality\n",
    "        good_sleep = feedback_df[feedback_df['sleep_hrs'] >= 7]['workout_completion_pct'].mean()\n",
    "        poor_sleep = feedback_df[feedback_df['sleep_hrs'] < 6]['workout_completion_pct'].mean()\n",
    "        print(f\"   Good sleep (‚â•7h): {good_sleep:.1f}% completion\")\n",
    "        print(f\"   Poor sleep (<6h): {poor_sleep:.1f}% completion\")\n",
    "    \n",
    "    print(f\"\\nüí° MODEL ADAPTATION INSIGHTS:\")\n",
    "    print(f\"   ‚úÖ The combined model learns from {len(feedback_df)} real user workouts\")\n",
    "    print(f\"   ‚úÖ Next retrain will be SMARTER based on actual performance data\")\n",
    "    print(f\"   ‚úÖ Recommendations are optimized for YOUR audience's capabilities\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No feedback data yet. Waiting for first users to complete workouts!\")\n",
    "    print(\"   This analytics will be available after ~5-10 user feedback submissions\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
